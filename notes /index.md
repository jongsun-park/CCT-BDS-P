## 1. [Introduction to BDSP](../pdfs/Lecture%201%20-%20Introduction%20to%20BDSP.pdf)

빅 데이터 저장 및 처리 소개

1. 빅 데이터 소개
2. 빅 데이터의 특성과 이해
3. 데이터 유형: 거래형 또는 분석형
4. ACID vs BASE (관계형(구식 접근법)과 비관계형(NoSQL))
5. 빅 데이터 아키텍처 및 처리
6. 데이터 및 저장 패러다임
7. 분산 컴퓨팅 개요
8. 요구 사항 및 도전 과제: 빅 데이터

빅 데이터의 정의와 중요성

- 빅 데이터의 사용: 빅 데이터는 우리의 일상생활에서 점점 더 많이 사용되고 있다.
- 데이터 생성: 소셜 네트워크, 모바일 애플리케이션, 인터넷 검색 등에서 방대한 양의 데이터가 생성되고 수집된다.
- 빅 데이터의 정의: "Big data"는 일반적인 데이터 처리 소프트웨어나 데이터베이스 관리 시스템(RDBMS)으로 분석하기 어려운 방대한 데이터 집합을 의미한다.
- 저장 방식의 변화: 데이터는 관계형 데이터베이스 관리 시스템 저장에서 NoSQL 저장으로 발전하고 있다.

빅 데이터의 특성 (다섯 가지 V):

- Volume (볼륨): 방대한 양의 데이터로 저장 및 처리 요구 사항에 도전이 된다.
- Velocity (속도): 데이터는 매우 빠른 속도로 생성된다.
- Variety (다양성): 데이터는 웹 로그, 사용자 트윗, 검색 패턴 등 다양한 출처에서 얻어진다.
- Veracity (진실성): 데이터의 신뢰성, 정확성 또는 진위성을 의미한다.
- Value (가치): 데이터는 높은 가치를 가져야 하며, 오래된 데이터는 제한된 가치를 가진다.

데이터 유형: 거래 및 분석

- 거래 시스템:
  - 거래 처리를 지원하는 시스템으로, ACID (Atomicity, Consistency, Isolation, Durability) 속성을 준수한다.
  - 각 거래에 대해 고유하게 식별되는 데이터가 필요하다.
- 분석 시스템:
  - 데이터가 반드시 적절한 스키마를 따르지 않으며, 중복 및 결측값이 있을 수 있다.
  - 이러한 시스템은 데이터 분석에 더 적합하다.
- 빅 데이터와 분석 시스템:
  - 빅 데이터는 분석 시스템과 관련이 있으며, 이러한 시스템은 강한 일관성을 요구하지 않는다.

ACID와 BASE의 비교

- ACID의 도전: 분산 시스템에서 ACID 보장을 충족하는 것은 매우 도전적이다.
- BASE의 정의:
  - BASE는 Basically Available Soft state Eventual consistency의 약자이다.
  - 네트워크 장애 발생 시, 빅 데이터 시스템은 가용성을 제공하기 위해 일관성을 타협하는 경향이 있다.
- 주요 초점:
  - 이러한 시스템의 주요 초점은 가용성을 보장하는 것이며, 최종 일관성 모델이 따르게 된다.

빅 데이터 아키텍처

- 빅 데이터 처리 아키텍처:
  - 다양한 아키텍처가 빅 데이터 처리를 위해 사용될 수 있다.
  - 효율적인 실시간 데이터 처리 아키텍처는 확장 가능하고 내결함성이 있어야 하며, 배치 및 증분 업데이트를 지원해야 한다.
- 주요 아키텍처:
  - Lambda Architecture
  - Kappa Architecture

빅 데이터 처리 기술

- 도전 과제 해결 방안:
  - 더 크고 강력한 기계 구축
  - 다양한 클라우드 플랫폼을 활용하여 빅 데이터 처리 지원
- 기술 발전:
  - 기술 발전으로 방대한 양의 데이터를 저장할 수 있게 되었지만, 여전히 데이터 사용에 영향을 미치는 기술적 한계가 존재한다.
- 하드 드라이브 예시:
  - 1990년대의 일반 하드 드라이브: 1370 MB 용량, 4.4 MB/s 전송 속도
  - 2022년의 일반 하드 드라이브: 1 TB 용량, 100 MB/s 또는 200 MB/s 전송 속도

분산 컴퓨팅 개요

- 병렬 컴퓨팅:
  - 여러 컴퓨팅 자원을 동시에 사용하여 계산 문제를 해결하는 방식이다.
- 분산 컴퓨팅과의 관계:
  - 분산 시스템의 프로세서는 병렬성을 사용하며, 분산 시스템은 문제의 일부를 병렬로 해결하는 데 사용될 수 있다.

분산 데이터베이스의 정의

- 데이터베이스 서버:
  - 데이터베이스를 관리하는 소프트웨어이며, 클라이언트는 정보를 요청하고 서버로부터 서비스를 받는 애플리케이션이다.
- 분산 처리(DP):
  - 하나 이상의 컴퓨터(또는 프로세서)를 사용하여 애플리케이션을 실행하고 개별 작업을 수행하는 방식이다.
- 목표:
  - DP 시스템의 주요 목표는 사용자와 자원을 투명하고 개방적이며 확장 가능한 방식으로 연결하는 것이다.

빅 데이터의 요구 사항 및 도전 과제

- 주요 요구 사항:
  - Scalability (확장성)
  - Availability and Fault Tolerance (가용성 및 내결함성)
  - Efficient Network Setup (효율적인 네트워크 설정)
  - Flexibility (유연성)
  - Privacy and Access Control (개인정보 보호 및 접근 제어)
  - Elasticity (탄력성)
  - Batch Processing and Interactive Processing (배치 처리 및 상호작용 처리)
  - Efficient Storage (효율적인 저장)
  - Multi-tenancy (다중 임대)
  - Efficient Processing (효율적인 처리)
  - Efficient Scheduling (효율적인 스케줄링)

참고 자료 및 리소스

- 주요 참고 문헌:
  - "Big Data: Concepts, Technology, and Architecture", Balamurugan Balusamy 외, ISBN: 978-1-119-70187-3, 2021년 3월, 368페이지.
  - "Big Data Systems: A 360-degree Approach", Jawad Ahmed Shamsi 외, CRC Press, 2021.
  - "NoSQL Database for Storage and Retrieval of Data in Cloud", Ganesh Chandra Deka, CRC Press, 2017.
  - "Big Data: Principles And Best Practices Of Scalable Real-time Data Systems", Nathan Marz 외, Manning Publications, 2015.

## 2. [Hadoop Distributed File System (HDFS)](<//pdfs/Lecture%202%20-%20Hadoop%20Distributed%20File%20System%20(HDFS).pdf>)

주요 내용:

- Hadoop Distributed File System (HDFS): 대규모 데이터 세트를 분산 저장하고 처리하기 위한 오픈 소스 소프트웨어 플랫폼이다.
- 주요 목표: 데이터 세트가 단일 물리적 기계의 저장 용량을 초과할 때, 여러 기계에 걸쳐 데이터를 분할해야 한다.

하둡 소개 및 필요성

- 하둡 정의:
  - What is Hadoop?: 대규모 데이터 세트를 분산 저장하고 처리하기 위한 오픈 소스 소프트웨어 플랫폼이다.
- 필요성:
  - 데이터 크기: 데이터의 양이 너무 커서 테라바이트 단위로 발생한다.
  - 수직적 확장 한계: 디스크 탐색 시간, 하드웨어 고장, 처리 시간 등의 문제로 수직적 확장이 효과적이지 않다.
  - 수평적 확장: 수평적 확장은 선형적이며, HDFS는 수평적으로 확장 가능하다.

하둡 설계 목표

- HDFS 설계 목표:
  - 대규모 데이터 처리: 매우 큰 데이터 세트를 처리할 수 있도록 설계되었다.
  - 상품 하드웨어 배포: 일반적인 하드웨어에서 배포 가능하다.
  - 장애 허용: 높은 수준의 장애 허용성을 제공한다.
  - 스트리밍 접근: 파일 시스템 데이터에 대한 스트리밍 접근을 가능하게 한다.
- 데이터 크기: 메가바이트에서 페타바이트까지의 데이터 크기를 처리할 수 있다.

하둡 개념: 블록

- 블록 개념:
  - 블록 I/O: 디스크 수준에서 블록 I/O에 익숙하다.
  - HDFS 블록 크기: 기본적으로 128MB로 설정되어 있다.
  - 파일 분할: HDFS 파일은 블록 크기 단위로 나뉘어 독립적인 단위로 저장된다.
  - 블록 크기 이유: 큰 HDFS 블록 크기는 탐색 작업의 비용을 줄이기 위해 설정되었다.

하둡 개념: 네임노드와 데이터노드

- HDFS 아키텍처:
  - 마스터/슬레이브 구조: HDFS는 마스터/슬레이브(또는 마스터/워커) 아키텍처를 가지고 있다.
  - 네임노드: 마스터 역할을 하며, 파일 시스템 트리와 메타데이터를 유지 관리한다.
  - 데이터노드: 슬레이브 역할을 하며, 데이터 저장을 관리하고 클라이언트의 읽기/쓰기 요청을 처리한다.
  - 데이터 흐름: 사용자 데이터는 네임노드를 통과하지 않는다.

하둡 고가용성

- 고가용성 개념:
  - NameNode Failure: 네임노드의 장애를 처리하기 위한 방법이다.
  - 복제 및 백업:
  - Secondary NameNode: 네임스페이스 이미지를 주기적으로 병합한다.
  - Checkpoint Node: 네임노드의 역할을 대체하며, 여러 개의 체크포인트 노드를 설정할 수 있다.
  - Backup Node: 체크포인트를 수행하고, 활성 네임노드와 동기화된 상태를 유지한다.
- 장애 허용성: HDFS는 활성-대기 구성으로 고가용성을 제공한다.

하둡 데이터 흐름: 파일 읽기

- 파일 읽기 과정:
  - 클라이언트 호출: 클라이언트는 FileSystem 객체에서 open()을 호출한다.
  - 네임노드 RPC: DistributedFileSystem은 네임노드에 RPC를 통해 파일의 첫 번째 블록 위치를 요청한다.
  - 데이터노드 주소 반환: 네임노드는 블록의 복사본을 가진 데이터노드의 주소를 반환한다.
  - FSDataInputStream: 클라이언트는 FSDataInputStream을 통해 데이터에 접근한다.

하둡 데이터 흐름: 파일 쓰기

- 파일 쓰기 과정:
  - 파일 생성: 클라이언트는 DistributedFileSystem에서 create()를 호출하여 파일을 생성한다.
  - 네임노드 확인: 네임노드는 파일이 이미 존재하지 않는지, 클라이언트가 필요한 권한을 가지고 있는지 확인한다.
  - 데이터 스트리밍: 클라이언트가 데이터를 쓸 때, DFSOutputStream은 패킷으로 나누어 내부 데이터 큐에 저장한다.
  - 데이터 파이프라인: 데이터는 여러 데이터노드에 걸쳐 스트리밍된다.

하둡 근접성 및 복제

- 근접성 개념:
  - 노드 간 거리 측정: 노드 간의 근접성을 측정하기 위해 대역폭을 사용한다.
  - 네트워크 구조: 네트워크는 트리 구조로 표현되며, 노드 간의 거리는 가장 가까운 공통 조상의 거리의 합으로 계산된다.
- 복제 배치:
  - 장애 허용성: 블록은 장애 허용성을 위해 복제된다.
  - 복제 수 지정: 애플리케이션은 필요한 복제 수를 지정할 수 있다.
  - 네임노드의 결정: 네임노드는 복제 배치에 대한 결정을 내린다.

참고 자료 및 저작권 고지

- 참고 자료:
  - Mastering Hadoop 3: Chanchal Singh, Manish Kumar, Packt Publishing, 2019.
  - Hadoop with Python: Zach Radtka; Donald Miner, O'Reilly Media, 2015.
  - Data Analysis with Python and PySpark: Jonathan Rioux, Manning Publications, 2022.

## 3. [MapReduce Design Patterns](//pdfs/Lecture%203%20-%20Mapreduce%20Design%20Patterns.pdf)

주요 내용:

- 빅 데이터 처리의 필요성과 중요성에 대한 설명이 포함되어 있다.
- 데이터 저장 및 처리 기술의 발전이 이루어지고 있음을 강조한다.

디자인 패턴 개요

- 정의: 디자인 패턴은 소프트웨어 설계에서 자주 발생하는 문제를 해결하기 위한 표준화된 솔루션을 제공하는 구조나 방법론을 말합니다. 이러한 패턴은 객체와 클래스 간의 상호작용을 설명하여, 개발자가 비슷한 문제를 해결할 때 참고할 수 있는 가이드라인을 제공합니다.
  목적:
  - 디자인 패턴은 일반적인 애플리케이션 디자인 문제에 대한 해결책을 제공한다.
  - 보일러플레이트 형태로 일반화된 솔루션을 제공하여 실제 문제에 적용할 수 있도록 한다.
- 시각화:
  - 디자인 패턴은 클래스 다이어그램을 사용하여 클래스 간의 관계와 행동을 보여줄 수 있다.
- 역사적 배경:
  - 객체 지향 프로그래밍은 1980년대에 등장하였으며, Smalltalk, C++, Objective C와 같은 여러 언어가 이 개념을 기반으로 발전하였다.

MapReduce 디자인 패턴

- 정의: MapReduce는 수백 대의 컴퓨터에 저장된 데이터를 처리하기 위한 컴퓨팅 패러다임이다.
- 중요성:
  - 이 패러다임은 구글과 하둡에 의해 최근에 널리 알려지게 되었다.
  - MapReduce는 대량의 데이터를 처리하고 생성하기 위해 작업을 독립적인 태스크로 나누어 클러스터에서 병렬로 실행할 수 있도록 한다.
- 디자인 패턴:
  - MapReduce 디자인 패턴은 일반적인 데이터 조작 문제를 해결하기 위한 템플릿이다.
- 구성 요소:
  - MapReduce는 맵, 셔플 및 정렬, 리듀스의 세 가지 주요 단계로 구성된다.

MapReduce의 데이터 흐름

- 구성 단계:
- MapReduce 프레임워크는 세 가지 주요 단계로 구성된다:
  1. 맵:맵 단계에서 함수(맵퍼)는 일련의 키-값 쌍(<k, v>)을 처리한다.
  2. 셔플 및 정렬: 맵 단계의 중간 출력이 리듀서로 이동하는 과정이다.
  3. 리듀스: 리듀서는 각 고유 키에 대한 값을 집계하고, 0개 이상의 출력 키-값 쌍을 생성한다.
- 예시: 맵퍼의 목적은 문장을 단어로 변환하는 것이다.

Shuffle 및 정렬 단계

- 정의:
  - MapReduce의 두 번째 단계는 셔플 및 정렬이다.
- 과정:
  - 맵퍼가 완료되면, 맵 단계의 중간 출력이 리듀서로 이동한다.
  - 이 과정은 셔플링이라고 하며, 파티셔너에 의해 처리된다.
- 파티셔너:
  - 파티셔너는 맵퍼의 출력 키와 리듀서의 수를 받아서 의도된 리듀서의 인덱스를 반환한다.
- 정렬:
  - 리듀서가 데이터를 처리하기 전에 중간 키와 값이 정렬된다.

Reduce 단계 설명

- 정의:
  - MapReduce의 세 번째 단계는 리듀스 단계이다.
- 기능:
  - 리듀서는 각 고유 키에 대한 값을 집계하고, 0개 이상의 출력 키-값 쌍을 생성한다.
- 예시:
  - 리듀서의 목적은 특정 키에 대한 모든 값을 합산하는 것이다.
- 출력:
  - 리듀서는 입력 키와 입력 키 값의 합계를 포함하는 키-값 쌍을 출력한다.

하둡 스트리밍 개요

- 정의:
  - 하둡 스트리밍은 하둡 배포판에 포함된 유틸리티로, 맵퍼 및/또는 리듀서로서 임의의 실행 파일을 사용하여 MapReduce 작업을 생성할 수 있게 해준다.
- 기능:
  - Python, 셸 스크립트 또는 다른 언어를 맵퍼, 리듀서 또는 둘 다로 사용할 수 있다.
- 작동 방식:
  - 맵퍼와 리듀서는 표준 입력(stdin)에서 입력을 읽고, 표준 출력(stdout)으로 출력을 작성하는 실행 파일이다.
- 작업 제출:
  - 하둡 스트리밍 유틸리티는 MapReduce 작업을 생성하고 클러스터에 제출하며, 작업이 완료될 때까지 진행 상황을 모니터링한다.

Python 예제: WordCount

- 목적:
  - 하둡 스트리밍 유틸리티가 Python을 사용하여 하둡 클러스터에서 MapReduce 애플리케이션을 실행하는 방법을 보여준다.
- 구성:
  - WordCount 애플리케이션은 두 개의 Python 프로그램으로 구현된다: mapper.py와 reducer.py.
- mapper.py:
  - 이 프로그램은 WordCount의 맵 단계에서의 로직을 구현한다.
  - 데이터는 stdin에서 읽고, 줄을 단어로 나누어 각 단어와 그 중간 카운트를 stdout으로 출력한다.
- reducer.py:
  - 이 프로그램은 WordCount의 리듀스 단계에서의 로직을 구현한다.
  - mapper.py의 결과를 stdin에서 읽고, 각 단어의 발생 횟수를 합산하여 결과를 stdout으로 작성한다.

MapReduce 디자인 패턴 분류

- 분류:
  - MapReduce 패턴은 다음과 같이 분류된다:
    - 요약(Summarization)
    - 필터링(Filtering)
    - 조인(Join)
    - 데이터 조직(Data Organization)
    - 입력/출력(Input/Output)
    - 요약 패턴:
    - 데이터의 상위 수준 및 요약된 뷰를 생성하는 패턴이다.

요약 패턴 설명

- 기능:
  - 요약 패턴은 데이터의 상위 수준 및 요약된 뷰를 생성한다.
- 구체적인 요약 패턴:
  - 수치 요약(Numerical Summarisation):
    - 집계 값을 계산하는 일반적인 패턴이다.
  - 역 인덱스(Inverted Index):
    - 데이터 검색을 위한 구조이다.
  - 카운터를 이용한 카운팅(Counting with Counters):
    - 특정 이벤트의 발생 횟수를 세는 방법이다.

필터링 디자인 패턴

- 정의:
  - Top Ten 패턴은 최종적으로 얻고자 하는 레코드 수가 정해져 있는 패턴이다.
- 목적:
  - 데이터 세트에서 특정 기준에 따라 상대적으로 적은 수의 상위 K 레코드를 검색하는 것이다.
- 동기:
  - 이상치 분석은 데이터 분석에서 중요한 부분이며, 이러한 레코드는 일반적으로 데이터 세트에서 가장 흥미롭고 독특한 데이터이다.
- 사용 사례:
  - 이상치 분석
  - 흥미로운 데이터 선택
  - 매력적인 대시보드 생성

참고 문헌:

- Tom White, 2012, Hadoop The Definitive Guide, O’Reilly Publishing
- Zach Radtka; Donald Miner, 2015, Hadoop with Python, O'Reilly Media, Inc.
- Lublinsky B., Smith K. T. and Yakubovich A, 2013, Professional Hadoop Solutions, Wrox
- Holmes A, 2012, Hadoop in Practice, Manning Publications
- McKinney W., 2012, Python for Data Analysis, O'Reilly Media

## 4.[Apache Spark](//pdfs/Lecture%204%20-%20Apache%20Spark.pdf)

아파치 스파크 소개

- 아파치 스파크: 데이터 과학자들을 위한 소프트웨어 스택 이상의 의미를 가진다.
- 개발 환경: 애플리케이션을 구축할 때 운영 체제 위에서 개발하는 것과 유사하다.
- 서비스 제공: 아파치 스파크는 애플리케이션 개발을 용이하게 하기 위해 운영 체제가 제공하는 서비스와 유사한 기능을 제공한다.

아파치 스파크의 구성 요소

- 구성 요소: 아파치 스파크는 여러 구성 요소로 이루어져 있다.
  - Spark SQL: SQL 쿼리를 지원하는 구성 요소
  - Spark Streaming: 실시간 데이터 처리를 위한 구성 요소
  - MLlib: 머신러닝을 위한 라이브러리
  - GraphX: 그래프 처리 라이브러리
- 언어 지원: 스칼라(Scala), 자바(Java), 파이썬(Python), R을 지원한다.

RDD 기본 사항

- RDD 정의: RDD(Resilient Distributed Dataset)는 불변의 분산 객체 컬렉션이다.
- 파티션: 각 RDD는 여러 파티션으로 나뉘며, 클러스터의 서로 다른 노드에서 계산될 수 있다.
- 생성 방법:
  - 외부 데이터셋을 로드하여 생성
  - 드라이버 프로그램에서 객체 컬렉션을 분산하여 생성
- 작업 유형:
  - 변환(Transformations): 이전 RDD에서 새로운 RDD를 생성하는 작업
  - 액션(Actions): RDD를 기반으로 결과를 계산하여 드라이버 프로그램에 반환하거나 외부 저장소에 저장하는 작업

스파크와 맵리듀스 비교

- DAG 데이터 처리 엔진: 스파크는 고급 Directed Acyclic Graph(DAG) 데이터 처리 엔진을 사용한다.
- 효율성: 메모리 내 데이터 처리와 DAG 기반 데이터 처리 엔진의 결합으로 스파크는 매우 효율적이다.
- 비교:
  - 맵리듀스: 두 개의 정점(맵 작업과 리듀스 작업)으로 구성된 DAG
  - 스파크: 더 복잡한 DAG 구조를 통해 다양한 작업을 동시에 처리할 수 있다.

스파크 프로그래밍 패러다임

- 프로그래밍 모델: 스파크는 여러 프로그래밍 언어를 지원하는 통일된 프로그래밍 모델을 제공한다.
- 지원 언어: 스칼라, 자바, 파이썬, R을 지원하며, 각 언어 간의 기능적 동등성은 없다.
- REPL 기능: 스칼라, 파이썬, R의 REPL(Read, Evaluate, Print, Loop) 기능을 통해 인터랙티브한 코드 테스트가 가능하다.
- 드라이버 프로그램: 스파크 애플리케이션의 드라이버 프로그램은 SparkContext 객체로, 클러스터 매니저와 통신하여 작업을 실행한다.

스파크와 하둡 환경

- 클러스터 컴퓨팅: 아파치 스파크는 대규모 데이터 처리를 위한 클러스터 컴퓨팅 프레임워크이다.
- 맵리듀스와의 차이: 스파크는 맵리듀스를 실행 엔진으로 사용하지 않으며, 자체 분산 런타임을 사용한다.
- 하둡 통합: 스파크는 하둡과 밀접하게 통합되어 있으며, YARN에서 실행할 수 있다.
- 메모리 활용: 스파크는 작업 간에 대규모 작업 데이터셋을 메모리에 유지할 수 있는 능력으로 맵리듀스보다 더 높은 성능을 발휘한다.

스파크 아키텍처

- 구성 요소: 스파크 아키텍처는 여러 구성 요소로 이루어져 있으며, 각 요소는 데이터 처리의 효율성을 높인다.
- 에지 노드: 하둡 클러스터와 외부 네트워크 간의 인터페이스 역할을 한다.
- 데이터 소스: 스파크는 HDFS, Hive, Kafka, Cassandra, S3 등 다양한 데이터 소스에서 읽고 쓸 수 있다.

스파크 SQL 및 데이터프레임

- 데이터프레임: 데이터프레임은 관계형 데이터베이스의 테이블과 동등한 개념이다.
- Spark SQL: SQL 쿼리를 사용하여 데이터프레임을 쿼리할 수 있는 기능을 제공한다.
- HiveQL 지원: Spark SQL은 HiveQL을 통해 데이터 쿼리를 지원한다.

스파크 ML 및 머신러닝

- 머신러닝 라이브러리: 스파크는 두 가지 머신러닝 라이브러리인 spark.mllib과 spark.ml을 제공한다.
- 파이프라인: 머신러닝 워크플로우를 형성하는 Estimator와 Transformer의 체인으로 구성된다.
- 알고리즘: 분류, 회귀, 클러스터링, 협업 필터링 등 다양한 알고리즘을 제공한다.

스파크 스트리밍

- 실시간 데이터 처리: 스파크 스트리밍은 실시간 데이터 스트림을 처리하는 기능을 제공한다.
- 데이터 소스: Kafka, Flume, Twitter, Kinesis 등 다양한 소스에서 데이터를 수집할 수 있다.
- 배치 처리: 실시간 입력 데이터 스트림을 배치로 나누어 처리하여 최종 결과를 생성한다.

스파크 R 프로그래밍

- SparkR 패키지: R 데이터 과학자들이 클러스터에서 데이터 처리를 수행할 수 있도록 돕는다.
- 데이터프레임 변환: Spark 데이터프레임을 R 데이터프레임으로 변환하여 메모리 내에서 처리할 수 있다.
- ETL 대체: Spark와 R을 결합하여 전체 ETL 파이프라인을 대체할 수 있다.

주요 참고 문헌:

- "Learning Spark" - Holden Karau 외
- "Spark in Action" - Jean-Georges Perrin 외
- "Professional Hadoop Solutions" - Lublinsky 외
- 기타 자료: Hadoop 공식 문서 및 Google 검색 리포지토리에서 이미지 사용.
